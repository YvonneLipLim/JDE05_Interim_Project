{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the script...\n",
      "Filtered records count: 27980\n",
      "Unique resale prices: [ 341800.  388000.  395000. ... 1200888.  534388.  458988.]\n",
      "Successfully loaded 27980 records to PostgreSQL.\n",
      "Script completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # For data manipulation\n",
    "from sqlalchemy import create_engine # For database connectivity\n",
    "import psycopg2 # For PostgreSQL connectivity\n",
    "from psycopg2 import sql # For SQL queries\n",
    "from psycopg2.extras import execute_values # For bulk insert\n",
    "\n",
    "# Define constants\n",
    "CSV_FILE_PATH = '/Users/shawnwee/teams notes_Generation SCTP JDE 05/Week 5 Interim Project/ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv' # Update your file path\n",
    "DB_USER = 'postgres'             # Update with your PostgreSQL username\n",
    "DB_PASS = 'admin'                # Update with your PostgreSQL password\n",
    "DB_HOST = 'localhost'            # Update with your database host\n",
    "DB_PORT = '5432'                 # Update with your database port\n",
    "DB_NAME = 'data_gov_project'     # Update with your PostgreSQL database name\n",
    "\n",
    "# Define date range for filtering\n",
    "START_DATE = pd.Timestamp('2023-10-01')\n",
    "END_DATE = pd.Timestamp('2024-9-30')\n",
    "\n",
    "def load_data_from_csv(file_path):\n",
    "    \"\"\"Load data from a CSV file and filter by date range.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert 'month' to a datetime representing resale_date\n",
    "    df['resale_date'] = pd.to_datetime(df['month'], format='%Y-%m', errors='coerce')\n",
    "\n",
    "    # Convert numeric columns to appropriate types\n",
    "    df['floor_area_sqm'] = pd.to_numeric(df['floor_area_sqm'], errors='coerce')\n",
    "    df['resale_price'] = pd.to_numeric(df['resale_price'], errors='coerce')\n",
    "    df['lease_commence_year'] = pd.to_datetime(df['lease_commence_date'], errors='coerce').dt.year\n",
    "\n",
    "    # Add resale_id (sequential numbers starting from 1)\n",
    "    df['resale_id'] = range(1, len(df) + 1)  # Sequential numbers starting from 1\n",
    "        \n",
    "    # Prepare DataFrame and rename columns for PostgreSQL compatibility\n",
    "    processed_df = df.rename(columns={\n",
    "        'town': 'town_name',\n",
    "        'block': 'block_no',\n",
    "        'storey_range': 'storey_range'  # This remains unchanged\n",
    "    })\n",
    "\n",
    "    # Select relevant columns for PostgreSQL, excluding 'resale_id'\n",
    "    processed_df = processed_df[['resale_id', 'resale_date', 'town_name', 'flat_type', 'block_no', \n",
    "                                  'street_name', 'storey_range', 'floor_area_sqm', \n",
    "                                  'flat_model', 'lease_commence_year', 'remaining_lease', \n",
    "                                  'resale_price']]\n",
    "    \n",
    "    # Filter for valid date ranges\n",
    "    filtered_df = processed_df[(processed_df['resale_date'] >= START_DATE) & \n",
    "                                (processed_df['resale_date'] <= END_DATE)]\n",
    "\n",
    "    print(f\"Filtered records count: {len(filtered_df)}\")\n",
    "    print(\"Unique resale prices:\", filtered_df['resale_price'].unique())\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def load_data_to_postgres(data_frame):\n",
    "    \"\"\"Load the provided DataFrame into the PostgreSQL database.\"\"\"\n",
    "    # Create database engine for SQLAlchemy usage\n",
    "    engine = create_engine(f'postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "    # Prepare for bulk insert using psycopg2\n",
    "    conn = psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASS)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Prepare the insert query\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO resale_flat_txn (resale_id, resale_date, town_name, flat_type, block_no, street_name, \n",
    "                                      storey_range, floor_area_sqm, flat_model, lease_commence_year, \n",
    "                                      remaining_lease, resale_price)\n",
    "        VALUES %s\n",
    "    \"\"\")\n",
    "\n",
    "    # Prepare tuples for the insert query\n",
    "    data_tuples = [tuple(x) for x in data_frame.values]\n",
    "\n",
    "    try:\n",
    "        # Insert in batches using execute_values\n",
    "        execute_values(cur, insert_query, data_tuples, template=None, page_size=1000)\n",
    "        conn.commit()\n",
    "        print(f\"Successfully loaded {len(data_tuples)} records to PostgreSQL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data into PostgreSQL: {e}\")\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the script.\"\"\"\n",
    "    print(\"Starting the script...\")\n",
    "    \n",
    "    # Load the data from CSV\n",
    "    filtered_df = load_data_from_csv(CSV_FILE_PATH)\n",
    "    \n",
    "    # Load the filtered data into PostgreSQL\n",
    "    load_data_to_postgres(filtered_df)\n",
    "\n",
    "    print(\"Script completed.\")\n",
    "\n",
    "# Execute the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
